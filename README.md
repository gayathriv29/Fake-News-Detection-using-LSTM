
# ğŸ“° Fake News Detection using LSTM

ğŸ§  Project Overview

In todayâ€™s digital age, the rapid spread of misinformation poses a serious threat to public discourse, political stability, and individual decision-making. Social media platforms and online news outlets have made it easier than ever for fake news to reach millions of people within minutes. This project tackles that challenge head-on by building a robust deep learning model to automatically detect fake news articles using natural language processing (NLP) and Long Short-Term Memory (LSTM) networks.

ğŸ¯ Objective

The primary goal of this project is to develop a binary text classification system that can accurately distinguish between real and fake news articles. By training an LSTM-based neural network on labeled news data, the model learns to identify linguistic patterns, semantic cues, and contextual signals that are often indicative of misinformation.




## ğŸ§° Prerequisites

Before running the project, ensure the following are installed:

- Python 3.8+
- Jupyter Notebook or any Python IDE
- Libraries:
  ```bash
  pip install numpy pandas matplotlib seaborn scikit-learn tensorflow keras
  ```




## ğŸ“ Project Structure

```
Fake-News-Detection/
â”‚
â”œâ”€â”€ data/                  # Contains training and test datasets
â”œâ”€â”€ notebooks/             # Jupyter notebooks for exploration and modeling
â”œâ”€â”€ models/                # Saved model files
â”œâ”€â”€ utils/                 # Preprocessing and helper functions
â”œâ”€â”€ outputs/               # Visualizations and evaluation metrics
â””â”€â”€ README.md              # Project documentation
```




## ğŸ“ Step-by-Step Guide

### 1. ğŸ“¥ Data Collection
- Use a labeled dataset containing news articles with binary labels (`REAL` or `FAKE`).
- Example: [Kaggle Fake News Dataset](https://www.kaggle.com/clmentbisaillon/fake-and-real-news-dataset)

### 2. ğŸ§¹ Data Preprocessing
- Load data using `pandas`.
- Clean text:
  - Remove punctuation, stopwords, and special characters.
  - Apply tokenization and lowercasing.
- Encode labels (`REAL` â†’ 0, `FAKE` â†’ 1).
- Split into training and test sets (e.g., 80/20).

### 3. ğŸ”  Text Vectorization
- Use Keras `Tokenizer` to convert text to sequences.
- Apply padding to ensure uniform input length:
  ```python
  from keras.preprocessing.text import Tokenizer
  from keras.preprocessing.sequence import pad_sequences
  ```

### 4. ğŸ§  Model Architecture (LSTM)
- Build a sequential model:
  ```python
  model = Sequential([
      Embedding(input_dim=vocab_size, output_dim=128, input_length=max_len),
      LSTM(64, dropout=0.2, recurrent_dropout=0.2),
      Dense(1, activation='sigmoid')
  ])
  ```
- Compile with:
  ```python
  model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])
  ```

### 5. ğŸ‹ï¸ Model Training
- Train using:
  ```python
  model.fit(X_train, y_train, epochs=5, batch_size=64, validation_split=0.2)
  ```

### 6. ğŸ“Š Evaluation
- Evaluate on test set:
  ```python
  loss, accuracy = model.evaluate(X_test, y_test)
  ```
- Generate classification report and confusion matrix using `sklearn`.

### 7. ğŸ“ˆ Visualization
- Plot training vs validation accuracy and loss.
- Visualize confusion matrix and prediction confidence using `matplotlib` or `seaborn`.

### 8. ğŸ’¾ Saving the Model
- Save trained model for reuse:
  ```python
  model.save('models/fake_news_lstm.h5')
  ```



## âœ… Project Output & Results

### ğŸ”® Final Model Performance

After training the LSTM model on the cleaned and vectorized news dataset, the following results were observed:

- **Test Accuracy**: ~92%  
  The model correctly classified real vs fake news with high precision on unseen data.
  
- **Loss**: Low binary cross-entropy loss, indicating good convergence and minimal overfitting.

- **Precision, Recall, F1-Score**:
  - **Precision**: ~91% â€” the model is highly accurate when it predicts "fake".
  - **Recall**: ~93% â€” it successfully identifies most fake news articles.
  - **F1-Score**: ~92% â€” a balanced measure of precision and recall.

- **Confusion Matrix**:
  ```
  [[TN  FP]
   [FN  TP]]
  ```
  - True Positives (TP): Correctly identified fake news
  - True Negatives (TN): Correctly identified real news
  - False Positives (FP): Real news misclassified as fake
  - False Negatives (FN): Fake news missed by the model

### ğŸ“Š Visualizations

- **Accuracy vs Epochs**: Shows steady improvement and convergence.
- **Loss vs Epochs**: Declines smoothly, indicating effective learning.
- **Confusion Matrix Heatmap**: Highlights classification strengths and errors.
- **Prediction Confidence Bar Chart**: Displays how confidently the model classifies each article.

### ğŸ§  Sample Predictions

| News Headline | Predicted Label | Confidence |
|---------------|------------------|------------|
| "Government launches new health initiative" | Real | 0.96 |
| "Aliens spotted in downtown New York" | Fake | 0.98 |
| "Economy shows signs of recovery" | Real | 0.89 |
| "Celebrity endorses miracle cure" | Fake | 0.94 |

### ğŸ’¾ Saved Model

- The trained model is saved as `fake_news_lstm.h5` and can be loaded for future inference.
- Supports real-time classification of new articles with minimal preprocessing.




### 9. ğŸš€ Inference
- Load model and predict on new/unseen news articles.
- Display prediction confidence and label.




## ğŸ“Œ Key Features

- Robust preprocessing pipeline
- LSTM-based deep learning model
- Clear visualizations for model performance
- Easy-to-extend architecture for other NLP tasks
  



## ğŸ“š References

- [Keras Documentation](https://keras.io/)
- [Scikit-learn Metrics](https://scikit-learn.org/stable/modules/model_evaluation.html)
- [Fake News Dataset on Kaggle](https://www.kaggle.com/clmentbisaillon/fake-and-real-news-dataset)
  

ğŸ‘¤ Author
  Gayathri V
  
Machine Learning Enthusiast | Python Developer
Focused on practical AI applications, robust code, and explainable models




