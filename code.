#Import	Libraries
 !pip	install	tensorflow
 Requirement	already	satisfied:	tensorflow	in	c:\users\gayathri	v\anaconda3\lib\site-packages	(2.20.0)
 Requirement	already	satisfied:	absl-py>=1.0.0	in	c:\users\gayathri	v\anaconda3\lib\site-packages	(from	tensorflo
 w)	(2.3.1)
 Requirement	already	satisfied:	astunparse>=1.6.0	in	c:\users\gayathri	v\anaconda3\lib\site-packages	(from	tensor
 flow)	(1.6.3)
 Requirement	already	satisfied:	flatbuffers>=24.3.25	in	c:\users\gayathri	v\anaconda3\lib\site-packages	(from	ten
 sorflow)	(25.2.10)
 Requirement	already	satisfied:	gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1	in	c:\users\gayathri	v\anaconda3\lib\site-pac
 kages	(from	tensorflow)	(0.6.0)
 Requirement	already	satisfied:	google_pasta>=0.1.1	in	c:\users\gayathri	v\anaconda3\lib\site-packages	(from	tens
 orflow)	(0.2.0)
 Requirement	already	satisfied:	libclang>=13.0.0	in	c:\users\gayathri	v\anaconda3\lib\site-packages	(from	tensorf
 low)	(18.1.1)
 Requirement	already	satisfied:	opt_einsum>=2.3.2	in	c:\users\gayathri	v\anaconda3\lib\site-packages	(from	tensor
 flow)	(3.4.0)
 Requirement	already	satisfied:	packaging	in	c:\users\gayathri	v\anaconda3\lib\site-packages	(from	tensorflow)	(2
 4.2)
 Requirement	already	satisfied:	protobuf>=5.28.0	in	c:\users\gayathri	v\anaconda3\lib\site-packages	(from	tensorf
 low)	(5.29.3)
 Requirement	already	satisfied:	requests<3,>=2.21.0	in	c:\users\gayathri	v\anaconda3\lib\site-packages	(from	tens
 orflow)	(2.32.3)
 Requirement	already	satisfied:	setuptools	in	c:\users\gayathri	v\anaconda3\lib\site-packages	(from	tensorflow)	(
 72.1.0)
 Requirement	already	satisfied:	six>=1.12.0	in	c:\users\gayathri	v\anaconda3\lib\site-packages	(from	tensorflow)	
(1.17.0)
 Requirement	already	satisfied:	termcolor>=1.1.0	in	c:\users\gayathri	v\anaconda3\lib\site-packages	(from	tensorf
 low)	(3.1.0)
 Requirement	already	satisfied:	typing_extensions>=3.6.6	in	c:\users\gayathri	v\anaconda3\lib\site-packages	(from	
tensorflow)	(4.12.2)
 Requirement	already	satisfied:	wrapt>=1.11.0	in	c:\users\gayathri	v\anaconda3\lib\site-packages	(from	tensorflow
 )	(1.17.0)
 Requirement	already	satisfied:	grpcio<2.0,>=1.24.3	in	c:\users\gayathri	v\anaconda3\lib\site-packages	(from	tens
 orflow)	(1.75.0)
 Requirement	already	satisfied:	tensorboard~=2.20.0	in	c:\users\gayathri	v\anaconda3\lib\site-packages	(from	tens
 orflow)	(2.20.0)
 Requirement	already	satisfied:	keras>=3.10.0	in	c:\users\gayathri	v\anaconda3\lib\site-packages	(from	tensorflow
 )	(3.11.3)
 Requirement	already	satisfied:	numpy>=1.26.0	in	c:\users\gayathri	v\anaconda3\lib\site-packages	(from	tensorflow
 )	(2.1.3)
 Requirement	already	satisfied:	h5py>=3.11.0	in	c:\users\gayathri	v\anaconda3\lib\site-packages	(from	tensorflow)	
(3.12.1)
 Requirement	already	satisfied:	ml_dtypes<1.0.0,>=0.5.1	in	c:\users\gayathri	v\anaconda3\lib\site-packages	(from	
tensorflow)	(0.5.3)
 Requirement	already	satisfied:	charset-normalizer<4,>=2	in	c:\users\gayathri	v\anaconda3\lib\site-packages	(from	
requests<3,>=2.21.0->tensorflow)	(3.3.2)
 Requirement	already	satisfied:	idna<4,>=2.5	in	c:\users\gayathri	v\anaconda3\lib\site-packages	(from	requests<3,
 >=2.21.0->tensorflow)	(3.7)
 Requirement	already	satisfied:	urllib3<3,>=1.21.1	in	c:\users\gayathri	v\anaconda3\lib\site-packages	(from	reque
 sts<3,>=2.21.0->tensorflow)	(2.3.0)
 Requirement	already	satisfied:	certifi>=2017.4.17	in	c:\users\gayathri	v\anaconda3\lib\site-packages	(from	reque
 sts<3,>=2.21.0->tensorflow)	(2025.4.26)
 Requirement	already	satisfied:	markdown>=2.6.8	in	c:\users\gayathri	v\anaconda3\lib\site-packages	(from	tensorbo
 ard~=2.20.0->tensorflow)	(3.8)
 Requirement	already	satisfied:	pillow	in	c:\users\gayathri	v\anaconda3\lib\site-packages	(from	tensorboard~=2.20
 .0->tensorflow)	(11.1.0)
 Requirement	already	satisfied:	tensorboard-data-server<0.8.0,>=0.7.0	in	c:\users\gayathri	v\anaconda3\lib\site-p
 ackages	(from	tensorboard~=2.20.0->tensorflow)	(0.7.2)
 Requirement	already	satisfied:	werkzeug>=1.0.1	in	c:\users\gayathri	v\anaconda3\lib\site-packages	(from	tensorbo
 ard~=2.20.0->tensorflow)	(3.1.3)
 Requirement	already	satisfied:	wheel<1.0,>=0.23.0	in	c:\users\gayathri	v\anaconda3\lib\site-packages	(from	astun
 parse>=1.6.0->tensorflow)	(0.45.1)
 Requirement	already	satisfied:	rich	in	c:\users\gayathri	v\anaconda3\lib\site-packages	(from	keras>=3.10.0->tens
 orflow)	(13.9.4)
 Requirement	already	satisfied:	namex	in	c:\users\gayathri	v\anaconda3\lib\site-packages	(from	keras>=3.10.0->ten
 sorflow)	(0.1.0)
 Requirement	already	satisfied:	optree	in	c:\users\gayathri	v\anaconda3\lib\site-packages	(from	keras>=3.10.0->te
 nsorflow)	(0.17.0)
 Requirement	already	satisfied:	MarkupSafe>=2.1.1	in	c:\users\gayathri	v\anaconda3\lib\site-packages	(from	werkze
 ug>=1.0.1->tensorboard~=2.20.0->tensorflow)	(3.0.2)
 Requirement	already	satisfied:	markdown-it-py>=2.2.0	in	c:\users\gayathri	v\anaconda3\lib\site-packages	(from	ri
 ch->keras>=3.10.0->tensorflow)	(2.2.0)
 Requirement	already	satisfied:	pygments<3.0.0,>=2.13.0	in	c:\users\gayathri	v\anaconda3\lib\site-packages	(from	
rich->keras>=3.10.0->tensorflow)	(2.19.1)
 Requirement	already	satisfied:	mdurl~=0.1	in	c:\users\gayathri	v\anaconda3\lib\site-packages	(from	markdown-it-p
 y>=2.2.0->rich->keras>=3.10.0->tensorflow)	(0.1.0)


 import	numpy	as	np
 import	pandas	as	pd
 import	matplotlib.pyplot	as	plt
 import	re
 import	nltk
 from	sklearn.model_selection	import	train_test_split
 from	sklearn.metrics	import	classification_report,	confusion_matrix
 from	tensorflow.keras.preprocessing.text	import	Tokenizer
 from	tensorflow.keras.preprocessing.sequence	import	pad_sequences
 from	tensorflow.keras.models	import	Sequential
 from	tensorflow.keras.layers	import	Embedding,	LSTM,	Dense,	Dropout


 #Load	Dataset
 fake	=	pd.read_csv("Fake.csv")
 true	=	pd.read_csv("True.csv")


 #	Add	labels
 fake['label']	=	1
 true['label']	=	0


 #	Combine	datasets
 df	=	pd.concat([fake,	true],	axis=0).reset_index(drop=True)
 print(df.shape)
 print(df.head())
 (44898,	5)
 title		\
 0			Donald	Trump	Sends	Out	Embarrassing	New	Year’...			
1			Drunk	Bragging	Trump	Staffer	Started	Russian	...			
2			Sheriff	David	Clarke	Becomes	An	Internet	Joke...			
3			Trump	Is	So	Obsessed	He	Even	Has	Obama’s	Name...			
4			Pope	Francis	Just	Called	Out	Donald	Trump	Dur...			
text	subject		\
 0		Donald	Trump	just	couldn	t	wish	all	Americans	...				
1		House	Intelligence	Committee	Chairman	Devin	Nu...				
2		On	Friday,	it	was	revealed	that	former	Milwauk...				
3		On	Christmas	day,	Donald	Trump	announced	that	...				
4		Pope	Francis	used	his	annual	Christmas	Day	mes...				
date		label		
0		December	31,	2017						
1		
1		December	31,	2017						
2		December	30,	2017						
3		December	29,	2017						
4		December	25,	2017						
#	Preprocessing	Dataset
 1		
1		
1		
1		
News			
News			
News			
News			
News	


def	clean_text(text):
 text	=	re.sub(r'[^a-zA-Z]',	'	',	text)		#	Remove	special	characters	and	numbers
 text	=	text.lower()		#	Convert	to	lowercase
 text	=	text.split()			#	Tokenize	by	whitespace																		
 return	"	".join(text)		 #	Rejoin	into	cleaned	string
 df['clean_text']	=	df['text'].apply(clean_text)


 #	Data	Encoding
 X	=	df['clean_text'].values
 y	=	df['label'].values


 #		Variables	Setup
 max_words	=	10000		#	vocab	size
 max_len	=	100				# max	length	of	sequences


 #	Tokenization
 tokenizer	=	Tokenizer(num_words=max_words,	split='	')
 tokenizer.fit_on_texts(X)
 X_seq	=	tokenizer.texts_to_sequences(X)
 X_pad	=	pad_sequences(X_seq,	maxlen=max_len)



 #	Splitting	Data	for	Training	and	Testing
X_train,	X_test,	y_train,	y_test	=	train_test_split(
 X_pad,	y,	test_size=0.2,	random_state=42
 )


 #	Test	the	Model	&	Training	the	Model	(LSTM)
 from	tensorflow.keras.models	import	Sequential
 from	tensorflow.keras.layers	import	Embedding,	LSTM,	Dense,	Dropout,	Bidirectional
 from	tensorflow.keras.callbacks	import	EarlyStopping


 #	Define	model
 model	=	Sequential()
 model.add(Embedding(max_words,	128))
 model.add(Bidirectional(LSTM(128,	dropout=0.3,	recurrent_dropout=0.3)))
 model.add(Dense(64,	activation='relu'))
 model.add(Dropout(0.5))
 model.add(Dense(1,	activation='sigmoid'))

 #	Compile
 model.compile(loss='binary_crossentropy',	optimizer='adam',	metrics=['accuracy'])

 #	Build	model	so	summary	works
 model.build(input_shape=(None,	max_len))

 #	Print	model	summary
 model.summary()

 #	Early	stopping	(example)
 early_stop	=	EarlyStopping(monitor='val_loss',	patience=2,	restore_best_weights=True)

 #	Dummy	data	for	example	(replace	with	your	preprocessed	dataset)
 X_train	=	np.random.randint(1,	max_words,	size=(1000,	max_len))
 y_train	=	np.random.randint(0,	2,	size=(1000,))
 X_test	=	np.random.randint(1,	max_words,	size=(200,	max_len))
 y_test	=	np.random.randint(0,	2,	size=(200,))

 #	Train
 history	=	model.fit(X_train,	y_train, epochs=5, batch_size=32, validation_data= (X_test,	y_test), callbacks=[early_stop], verbose=1)

 Model:	"sequential_6"
 ┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓
 ┃	Layer	(type)																				
┃	Output	Shape											
┃							
Param	#	┃
 ┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩
 │	embedding_6	(Embedding)									
│	(None,	100,	128)							
│					
1,280,000	│
 ├─────────────────────────────────┼────────────────────────┼───────────────┤
 │	bidirectional_6	(Bidirectional)	│	(None,	256)												
│							
263,168	│
 ├─────────────────────────────────┼────────────────────────┼───────────────┤
 │	dense_12	(Dense)																
│	(None,	64)													
│								
16,448	│
 ├─────────────────────────────────┼────────────────────────┼───────────────┤
 │	dropout_6	(Dropout)													
│	(None,	64)													
│													
0	│
 ├─────────────────────────────────┼────────────────────────┼───────────────┤
 │	dense_13	(Dense)																
│	(None,	1)														
│												
65	│
 └─────────────────────────────────┴────────────────────────┴───────────────┘
 Total	params:	1,559,681	(5.95	MB)
 Trainable	params:	1,559,681	(5.95	MB)
 Non-trainable	params:	0	(0.00	B)
 Epoch	1/5
 32/32	━━━━━━━━━━━━━━━━━━━━	15s	339ms/step	-	accuracy:	0.4730	-	loss:	0.6941	-	val_accuracy:	0.5300	-	val_loss:	0
 .6923
 Epoch	2/5
 32/32	━━━━━━━━━━━━━━━━━━━━	10s	303ms/step	-	accuracy:	0.7040	-	loss:	0.6514	-	val_accuracy:	0.5600	-	val_loss:	0
 .6895
 Epoch	3/5
 32/32	━━━━━━━━━━━━━━━━━━━━	10s	300ms/step	-	accuracy:	0.9480	-	loss:	0.2797	-	val_accuracy:	0.5150	-	val_loss:	0
 .9313
 Epoch	4/5
 32/32	━━━━━━━━━━━━━━━━━━━━	10s	301ms/step	-	accuracy:	0.9970	-	loss:	0.0242	-	val_accuracy:	0.5000	-	val_loss:	1
 .2387
 #	Sample	Prediction
 sample_text	=	["Breaking	news!	The	president	resigns	after	scandal."]
 seq	=	tokenizer.texts_to_sequences(sample_text)
 padded	=	pad_sequences(seq,	maxlen=max_len)
prediction	=	model.predict(padded)
 print("Prediction:",	"Fake	News"	if	prediction	>	0.5	else	"Real	News")
 1/1	━━━━━━━━━━━━━━━━━━━━	2s	2s/step
 Prediction:	Real	News


 #	Visualization	for	accuracy	of	fake	news
 plt.plot(history.history['accuracy'],	label='Train	Accuracy')
 plt.plot(history.history['val_accuracy'],	label='Val	Accuracy')
 plt.title('Accuracy	over	Epochs')
 plt.xlabel('Epochs')
 plt.ylabel('Accuracy')
 plt.legend()
 plt.show()
 plt.plot(history.history['loss'],	label='Train	Loss')
 plt.plot(history.history['val_loss'],	label='Val	Loss')
 plt.title('Loss	over	Epochs')
 plt.xlabel('Epochs')
 plt.ylabel('Loss')
 plt.legend()
 plt.show()


 #	Evaluation	on	Test	Data
 y_pred	=	(model.predict(X_test)	>	0.5).astype("int32")
 print("\nClassification	Report:\n",	classification_report(y_test,	y_pred))
 print("\nConfusion	Matrix:\n",	confusion_matrix(y_test,	y_pred))
7/7	━━━━━━━━━━━━━━━━━━━━	2s	215ms/step
 Classification	Report:
															precision				recall		f1-score			support
											0							0.60						0.49						0.54							106
											1							0.53						0.64						0.58								94
				accuracy																											0.56							200
			macro	avg							0.57						0.56						0.56							200
 weighted	avg							0.57						0.56						0.56							20


 Confusion	Matrix:
	[[52	54]
	[34	60]]
